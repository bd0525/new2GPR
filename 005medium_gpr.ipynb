{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import (\n",
    "    RBF, Matern, RationalQuadratic, ExpSineSquared, WhiteKernel, \n",
    "    ConstantKernel as C\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "class GaussianProcessSolver:\n",
    "    \"\"\"\n",
    "    A class for Gaussian Process regression that allows for customization\n",
    "    of kernels and optimization of hyperparameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel_type='rbf', optimize_hyperparams=True, random_state=None):\n",
    "        \"\"\"\n",
    "        Initialize the Gaussian Process Solver.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        kernel_type : str, default='rbf'\n",
    "            The type of kernel to use. Options: 'rbf', 'matern', 'rational_quadratic', \n",
    "            'exp_sine_squared', or 'composite'.\n",
    "        optimize_hyperparams : bool, default=True\n",
    "            Whether to optimize the hyperparameters during fitting.\n",
    "        random_state : int or None, default=None\n",
    "            Random seed for reproducibility.\n",
    "        \"\"\"\n",
    "        self.kernel_type = kernel_type\n",
    "        self.optimize_hyperparams = optimize_hyperparams\n",
    "        self.random_state = random_state\n",
    "        self.model = None\n",
    "        self._set_kernel()\n",
    "        \n",
    "    def _set_kernel(self):\n",
    "        \"\"\"Set the kernel based on the specified kernel_type.\"\"\"\n",
    "        if self.kernel_type == 'rbf':\n",
    "            # Radial Basis Function kernel\n",
    "            self.kernel = C(1.0) * RBF(length_scale=1.0) + WhiteKernel(noise_level=0.1)\n",
    "        elif self.kernel_type == 'matern':\n",
    "            # Matérn kernel\n",
    "            self.kernel = C(1.0) * Matern(length_scale=1.0, nu=1.5) + WhiteKernel(noise_level=0.1)\n",
    "        elif self.kernel_type == 'rational_quadratic':\n",
    "            # Rational Quadratic kernel\n",
    "            self.kernel = C(1.0) * RationalQuadratic(length_scale=1.0, alpha=0.1) + WhiteKernel(noise_level=0.1)\n",
    "        elif self.kernel_type == 'exp_sine_squared':\n",
    "            # Exponential Sine Squared kernel (periodic)\n",
    "            self.kernel = C(1.0) * ExpSineSquared(length_scale=1.0, periodicity=1.0) + WhiteKernel(noise_level=0.1)\n",
    "        elif self.kernel_type == 'composite':\n",
    "            # A composite kernel combining RBF and Matérn\n",
    "            self.kernel = C(1.0) * (\n",
    "                RBF(length_scale=1.0) + \n",
    "                Matern(length_scale=1.0, nu=1.5)\n",
    "            ) + WhiteKernel(noise_level=0.1)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported kernel type: {self.kernel_type}\")\n",
    "            \n",
    "        # Initialize the Gaussian Process Regressor with the chosen kernel\n",
    "        self.model = GaussianProcessRegressor(\n",
    "            kernel=self.kernel,\n",
    "            alpha=1e-10,  # numerical stability\n",
    "            normalize_y=True,\n",
    "            n_restarts_optimizer=10,\n",
    "            random_state=self.random_state,\n",
    "            optimizer=None if not self.optimize_hyperparams else 'fmin_l_bfgs_b'\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the Gaussian Process model to the training data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training input samples.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Target values.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        \"\"\"\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        # Store the optimized kernel parameters\n",
    "        self.optimized_kernel = self.model.kernel_\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self, X_test, return_std=False, return_cov=False):\n",
    "        \"\"\"\n",
    "        Make predictions using the fitted Gaussian Process model.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_test : array-like of shape (n_samples, n_features)\n",
    "            Test input samples.\n",
    "        return_std : bool, default=False\n",
    "            If True, return the standard deviation of the prediction along with the mean.\n",
    "        return_cov : bool, default=False\n",
    "            If True, return the covariance of the prediction along with the mean.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        y_pred : array-like of shape (n_samples,)\n",
    "            Predicted mean values.\n",
    "        y_std : array-like of shape (n_samples,), optional\n",
    "            Standard deviation of predictive distribution at test points.\n",
    "        y_cov : array-like of shape (n_samples, n_samples), optional\n",
    "            Covariance of joint predictive distribution at test points.\n",
    "        \"\"\"\n",
    "        if X_test.ndim == 1:\n",
    "            X_test = X_test.reshape(-1, 1)\n",
    "            \n",
    "        if return_std and return_cov:\n",
    "            raise ValueError(\"Cannot return both std and cov.\")\n",
    "        \n",
    "        if return_std:\n",
    "            return self.model.predict(X_test, return_std=True)\n",
    "        elif return_cov:\n",
    "            return self.model.predict(X_test, return_cov=True)\n",
    "        else:\n",
    "            return self.model.predict(X_test)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        \"\"\"\n",
    "        Return the coefficient of determination R^2 of the prediction.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Test input samples.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            True target values.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        score : float\n",
    "            R^2 of the prediction.\n",
    "        \"\"\"\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        return self.model.score(X, y)\n",
    "    \n",
    "    def get_kernel_params(self):\n",
    "        \"\"\"\n",
    "        Get the optimized kernel parameters.\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        params : dict\n",
    "            Dictionary containing the optimized kernel parameters.\n",
    "        \"\"\"\n",
    "        if hasattr(self, 'optimized_kernel'):\n",
    "            return self.optimized_kernel.get_params()\n",
    "        else:\n",
    "            return self.kernel.get_params()\n",
    "    \n",
    "    def plot_fit(self, X_train, y_train, X_test=None, y_test=None, n_samples=100, \n",
    "                 plot_samples=False, figsize=(10, 6)):\n",
    "        \"\"\"\n",
    "        Plot the Gaussian Process model fit.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_train : array-like of shape (n_samples, n_features)\n",
    "            Training input samples.\n",
    "        y_train : array-like of shape (n_samples,)\n",
    "            Training target values.\n",
    "        X_test : array-like of shape (n_test_samples, n_features), optional\n",
    "            Test input samples. If not provided, will use a linspace over the range of X_train.\n",
    "        y_test : array-like of shape (n_test_samples,), optional\n",
    "            Test target values. Only used for plotting if X_test is provided.\n",
    "        n_samples : int, default=100\n",
    "            Number of sample points to use for prediction if X_test is not provided.\n",
    "        plot_samples : bool, default=False\n",
    "            Whether to plot sample functions from the posterior.\n",
    "        figsize : tuple, default=(10, 6)\n",
    "            Figure size.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        fig : matplotlib.figure.Figure\n",
    "            The figure containing the plot.\n",
    "        \"\"\"\n",
    "        if X_train.ndim == 1:\n",
    "            X_train = X_train.reshape(-1, 1)\n",
    "        \n",
    "        # Create prediction points if X_test is not provided\n",
    "        if X_test is None:\n",
    "            X_min, X_max = X_train.min(), X_train.max()\n",
    "            X_test = np.linspace(X_min - 0.1 * (X_max - X_min), \n",
    "                                 X_max + 0.1 * (X_max - X_min), \n",
    "                                 n_samples).reshape(-1, 1)\n",
    "        elif X_test.ndim == 1:\n",
    "            X_test = X_test.reshape(-1, 1)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_mean, y_std = self.model.predict(X_test, return_std=True)\n",
    "        \n",
    "        # Create the figure\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        \n",
    "        # Plot training data\n",
    "        ax.scatter(X_train, y_train, color='blue', label='Training data')\n",
    "        \n",
    "        # Plot test data if provided\n",
    "        if y_test is not None:\n",
    "            ax.scatter(X_test, y_test, color='green', label='Test data')\n",
    "        \n",
    "        # Sort X_test for proper plotting\n",
    "        sort_idx = np.argsort(X_test.flatten())\n",
    "        X_test_sorted = X_test[sort_idx]\n",
    "        y_mean_sorted = y_mean[sort_idx]\n",
    "        \n",
    "        # Plot the mean prediction\n",
    "        ax.plot(X_test_sorted, y_mean_sorted, color='red', label='Mean prediction')\n",
    "        \n",
    "        if plot_samples:\n",
    "            # Plot sample functions from the posterior\n",
    "            samples = self.model.sample_y(X_test_sorted, n_samples=10)\n",
    "            for i in range(samples.shape[1]):\n",
    "                ax.plot(X_test_sorted, samples[:, i], color='gray', alpha=0.3, \n",
    "                       linewidth=0.8)\n",
    "        else:\n",
    "            # Plot the uncertainty intervals\n",
    "            y_std_sorted = y_std[sort_idx]\n",
    "            ax.fill_between(X_test_sorted.flatten(), \n",
    "                           y_mean_sorted - 2 * y_std_sorted,\n",
    "                           y_mean_sorted + 2 * y_std_sorted, \n",
    "                           alpha=0.2, color='red', label='±2 std')\n",
    "        \n",
    "        # Set labels and title\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_ylabel('Viscosity')\n",
    "        ax.set_title(f'Gaussian Process Regression with {self.kernel_type.capitalize()} Kernel')\n",
    "        ax.legend()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def evaluate(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Evaluate the model performance on test data.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_test : array-like of shape (n_samples, n_features)\n",
    "            Test input samples.\n",
    "        y_test : array-like of shape (n_samples,)\n",
    "            True target values.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        metrics : dict\n",
    "            Dictionary containing evaluation metrics.\n",
    "        \"\"\"\n",
    "        if X_test.ndim == 1:\n",
    "            X_test = X_test.reshape(-1, 1)\n",
    "            \n",
    "        y_pred = self.predict(X_test)\n",
    "        \n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        return {\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2\n",
    "        }\n",
    "    \n",
    "    def sample_posterior(self, X, n_samples=20):\n",
    "        \"\"\"\n",
    "        Sample functions from the posterior distribution.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Input points.\n",
    "        n_samples : int, default=10\n",
    "            Number of samples to draw.\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        samples : array-like of shape (n_samples, n_input_points)\n",
    "            Sampled function values at the input points.\n",
    "        \"\"\"\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1)\n",
    "            \n",
    "        return self.model.sample_y(X, n_samples=n_samples)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOg85XtlUSBVicdrTEjS1Fh",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
