{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Statistics\" is a function of data.\n",
    "\n",
    "A **sufficient statistic** $t(d)$ has the following properties:\n",
    "> $p(\\theta \\mid d) = p(\\theta \\mid t(d))$, example:<br><br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;For $d\\sim\\mathcal{U}(a,b)$, $\\theta = (a,b)$, then $p(\\theta\\mid d) = p(\\theta \\mid max(d), min(d))$<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;So for this case $t(d) = (max(d), min(d))$ is a sufficient statistic<br>\n",
    "  &nbsp;&nbsp;&nbsp;&nbsp;$p(\\theta \\mid t(d)) \\propto p(t(d) \\mid \\theta) p(\\theta)$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact sufficient statistics are rarely available. Let's look at \"locally sufficient statistics\".<br>\n",
    "There are functions of the data that are \"nearly\" suffcient in the neighbirhood of a \"fiducial\" parameter $\\theta_{\\text{fid}}$.\n",
    "\n",
    "Consider the log likelihood in a neighborhood around $\\theta_{\\text{fid}}$:<br>\n",
    "$\\ln p(d\\mid \\theta_{\\text{fid}}+\\Delta \\theta) = \\ln p(d\\mid \\theta_{\\text{fid}}) + \\partial_{\\theta_i} \\ln p(d\\mid \\theta_{\\text{fid}}) \\Delta \\theta_i + \\frac{1}{2} \\partial_{\\theta_i}\\partial_{\\theta_j} \\ln p(d\\mid \\theta_{\\text{fid}}) \\Delta \\theta_i \\Delta \\theta_j + \\cdots \\quad \\Leftarrow$ \"asymptotic\" expansion.<br>\n",
    "- $\\partial_{\\theta_i} \\ln p(d\\mid \\theta_{\\text{fid}}) \\Delta \\theta_i$ is the leading order term coupling $\\Delta \\theta$ and $d$, $s(d)_i = \\partial_{\\theta_i} \\ln p(d\\mid \\theta_{\\text{fid}})$ is the Fisher score function;<br>\n",
    "- $\\partial_{\\theta_i}\\partial_{\\theta_j} \\ln p(d\\mid \\theta_{\\text{fid}}) = -K_{ij}$, K is the curvature / Hessian matrix.<br>\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "<s(d)>_{d\\sim p(d\\mid \\theta_{\\text{fid}})} &= \\int \\partial_{\\theta_i} \\ln p |_{\\theta_{\\text{fid}}} p |_{\\theta_{\\text{fid}}} dd \\\\\n",
    "&= \\int \\frac{\\partial_{\\theta_i} p}{p} p dd \\\\\n",
    "&= \\partial_{\\theta_i} \\int p(d\\mid \\theta_{\\text{fid}}) dd \\\\\n",
    "&= \\partial_{\\theta_i} {1} = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$\\Rightarrow$ Average log likelihood is quadratic around $\\theta_{\\text{fid}}$.\n",
    "\n",
    "Now let's find $\\hat{\\theta}$ that maximizes $\\ln p(d\\mid \\hat{\\theta})$.\n",
    "\n",
    "$\\partial_{\\Delta \\theta} p |_{\\Delta \\theta = \\hat{\\theta} - \\theta_{\\text{fid}}} = 0 = s_i - K_{ij} \\Delta \\theta_j$\n",
    "\n",
    "$\\hat{\\theta} = \\theta_{\\text{fid}} + K_{ij}^{-1} s_j$, \"Quadratic maximum likelihood\".\n",
    "\n",
    "Iterating this $\\Rightarrow$ Maximum likelihood estimate, Newton-Raphson method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's replace K with F (Fisher information matrix), where $F = <K>$\n",
    "\n",
    "$\\hat{\\theta}_i = \\theta_{\\text{fid},i} + F_{ij}^{-1} s_j$\n",
    "\n",
    "> Do I lose information due to this? We will show that no other unbiased estimator has lower covarince. \n",
    "- Unbiased if $\\theta_{\\text{true}} = \\theta_{fid}$. $\\langle \\hat{\\theta}\\rangle = \\theta_{fid}$ asymptotically, thus unbiased; \n",
    "- Covariance;\n",
    "\n",
    "$\\text{Cov} \\hat{\\theta} = <F^{-1}ss^{\\top}F^{-1}> = F^{-1}<ss^{\\top}>F^{-1}$, where:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "<ss^{\\top}> &= \\int \\partial_{\\theta_i} \\ln p \\partial_{\\theta_j} \\ln p dd \\\\\n",
    "&= \\int \\partial_{\\theta_i} \\ln p \\frac{\\partial_{\\theta_j} p}{p} p dd \\\\\n",
    "&= -\\int \\partial_{\\theta_i}\\partial_{\\theta_j} \\ln p dd \\\\\n",
    "&= F\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus $\\operatorname{Cor}\\hat{\\theta})= F^{-1}FF^{-1}=F^{-1}$. Can we do betters?\n",
    "\n",
    "Assuming that $\\theta_{fid}$ is known, let's take any estimator $f(d)$ such that \n",
    "$$\\langle f(d)\\rangle_{d\\sim p(d\\mid \\theta_{fid})}=\\theta.$$ \n",
    "Then, $f(d)$ is unbiased.\n",
    "\n",
    "\n",
    "Consider \n",
    "$$\\begin{pmatrix}\n",
    "f \\\\ s\n",
    "\\end{pmatrix}$$\n",
    "$$\\operatorname{Cor}\\left( \\begin{pmatrix}\n",
    "f \\\\ s\n",
    "\\end{pmatrix}\\right) = \\begin{pmatrix}\n",
    "C_{ff} & C_{fs} \\\\\n",
    "C_{sf} & C_{ss}=F^{-1}\n",
    "\\end{pmatrix}\\succ 0$$\n",
    "Then \n",
    "$$\\begin{align*}\n",
    "\\left[C_{fs}\\right]_{ij} &= \\langle \\rangle \\\\\n",
    "&=\\langle (f_{i} - \\langle f_{i}\\rangle)s_j \\rangle \\\\\n",
    "&=\\langle f_{i}s_{j}\\rangle \\\\\n",
    "&= \\int f_{i} \\partial_{\\theta_{j}}\\ln p dd \\\\\n",
    "&= \\int f(d)_{i}\\frac{\\partial_{\\theta_{j}}p}{p} dd \\\\\n",
    "&= \\partial_{\\theta_{j}}\\int f(d)_{i} p dd\\\\\n",
    "&= \\partial_{\\theta_{j}}\\langle f_{i}\\rangle \\\\\n",
    "&= \\partial_{\\theta_{j}}\\theta_{i} \\\\\n",
    "&= \\delta_{ij}\n",
    "\\end{align*}$$\n",
    "where $s(d)$ is the most informative statistic (near $\\theta_{fid}$), thus locally sufficient. \n",
    "\n",
    "Remember that \n",
    "$$C_{f\\mid s}=C_{ff}-C_{fs}C_{ss}^{-1}C_{sf}$$ \n",
    "is a covariance matrix, thus $C_{f\\mid s}\\succ 0$. \n",
    "$$C_{ff}-F^{-1}\\succ 0 \\Longrightarrow C_{ff}\\succ F^{-1}$$\n",
    "which is the multi-variate generalization of the Cramer-Rao bound. \n",
    "\n",
    "Near $\\theta_{fid}$, $\\hat{\\theta}$ or $s$ are locally optimal compressed statistics, taking $\\operatorname{dim}(d) \\to \\operatorname{dim}\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick example**:<br><br>\n",
    "Gaussian likelihood with parameter-dependent mean. \n",
    "$$\\begin{align*}\n",
    "    \\ln p(d\\mid \\theta) &= \\text{const} -\\frac{1}{2} (d-\\mu(\\theta)^{\\top} N^{-1} (d-\\mu(\\theta))) \\\\\n",
    "    \\partial_{\\theta_{i}} \\ln p &= \\left( \\partial_{\\theta_{i}\\mu \\|_{\\theta_{\\theta_{fid}}}} \\right)^{\\top} N^{-1} \\left( d-\\mu(\\theta_{fid})\\right) \\\\\n",
    "    &=s\n",
    "\\end{align*}$$\n",
    "So a lowest sufficient statistics is $(\\partial_{\\theta_{i}}\\mu)N^{-1}d$. \n",
    "$$\\begin{align*}\n",
    "    F_{ij} &= \\operatorname{Cov}(s)_{ij} \\\\\n",
    "    &= \\partial_{\\theta}\\mu^{\\top} N^{-1} \\langle \\left(d-\\mu(\\theta_{fid})\\right) \\left(d-\\mu(\\theta_{fid}\\right)^{\\top}\\rangle N^{-1}(\\partial_{\\theta_{j}}\\mu) \\\\\n",
    "    &=\\partial_{\\theta}\\mu^{\\top} N^{-1} N N^{-1}(\\partial_{\\theta_{j}}\\mu) \\\\\n",
    "    &=\\partial_{\\theta}\\mu^{\\top} N^{-1}(\\partial_{\\theta_{j}}\\mu) \n",
    "\\end{align*}$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
