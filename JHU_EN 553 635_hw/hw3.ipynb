{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer:** Homework assignment for Johns Hopkins University, EN.553.635.01.SP25 – Bayesian Statistics for the Physical Sciences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.1** (Posterior Mean and Covariance via Integration by Differentiating) Using the posterior density\n",
    "$$p(\\theta \\mid d) \\propto p(d \\mid \\theta) p(\\theta) \\text{ ,}$$\n",
    "\n",
    "derive, by the method of \"integration by differentiating,\" the expressions for the posterior mean $\\mu_{\\theta \\mid d}$ and the posterior covariance $\\Sigma_{\\theta \\mid d}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**<br>\n",
    "Assume that prior is also Gaussian with $\\mu_{\\theta}=0$ and covariance $\\Sigma_{\\theta\\theta}$. Putting together the map functions we get $F$ with elements $\\{f_j(x_i)\\}_{ij}^{IJ}$. Now $d=F \\theta+n$. Notice that we can always add some mean functions $m$ to modele the residual $(d-m)$, so it is safe to assume the target mean $\\mu_d=0$.<br>\n",
    "$$\\mu_{d|\\theta} = \\mathbb{E}[F \\theta+n]=F \\theta+0$$\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(\\theta|d) &\\propto p(d|\\theta)p(\\theta) \\\\\n",
    "&\\propto \\exp{(-\\frac{1}{2} [(d-F\\theta)^{\\top} \\Sigma_{d|\\theta}^{-1}(d-F\\theta) + (\\theta-\\mu_{\\theta})^{\\top} \\Sigma_{\\theta\\theta}^{-1}(\\theta-\\mu_{\\theta})])}\n",
    "\\end{aligned}\n",
    "$$\n",
    "Then take the $1^{\\text{st}}$ derivative w.r.t. $\\theta$ and make it 0:<br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "F^{\\top} \\Sigma_{d|\\theta}^{-1} (d-F\\theta) - \\Sigma_{\\theta\\theta}^{-1}(\\theta - \\mu_{\\theta})&=0 \\\\\n",
    "(F^{\\top} \\Sigma_{d|\\theta}^{-1} F + \\Sigma_{\\theta\\theta}^{-1})\\theta &= F^{\\top}\\Sigma_{d|\\theta}^{-1}d+\\Sigma_{\\theta\\theta}^{-1}\\mu_{\\theta} \\\\\n",
    "\\mu_{\\theta|d} = \\theta &= \\frac{F^{\\top}\\Sigma_{d|\\theta}^{-1}d+\\Sigma_{\\theta\\theta}^{-1}\\mu_{\\theta}}{F^{\\top} \\Sigma_{d|\\theta}^{-1} F + \\Sigma_{\\theta\\theta}^{-1}} \n",
    "\\end{aligned}\n",
    "$$\n",
    "Take the $2^{\\text{nd}}$ derivative:<br>\n",
    "$$\\Sigma_{\\theta|d}=[F^{\\top}\\Sigma_{d|\\theta}^{-1}F+\\Sigma_{\\theta\\theta}^{-1}]^{-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2** (Limit of Posterior Parameters for a Non-informative Prior)  \n",
    "Using your result from Question 1, compute:  \n",
    "\n",
    "(a) $\\lim_{\\Sigma_{\\theta \\theta} \\to \\infty} \\mu_{\\theta|d}$.<br>  \n",
    "\n",
    "(b) $\\lim_{\\Sigma_{\\theta \\theta} \\to \\infty} \\Sigma_{\\theta|d}$.<br>  \n",
    "\n",
    "**Hint:** Interpret $\\Sigma_{\\theta \\theta} \\to \\infty$ as corresponding to an uninformative prior, so that $\\Sigma_{\\theta \\theta}^{-1} \\to 0$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**<br>\n",
    "(a) As the prior covariance $\\Sigma_{\\theta\\theta} \\to \\infty$, the precision(inverse of covariance) becomes 0, which leads to an uninformative prior,only the weighted data mean contributes to the posterior mean:<br>\n",
    "\\begin{aligned}\n",
    "\\mu_{\\theta|d} &= \\frac{F^{\\top}\\Sigma_{d|\\theta}^{-1}d+\\Sigma_{\\theta\\theta}^{-1}\\mu_{\\theta}}{F^{\\top} \\Sigma_{d|\\theta}^{-1} F + \\Sigma_{\\theta\\theta}^{-1}} \\\\\n",
    "&=\\frac{F^{\\top}\\Sigma_{d|\\theta}^{-1}d}{F^{\\top} \\Sigma_{d|\\theta}^{-1} F}\n",
    "\\end{aligned}\n",
    "<br>(b) The posterior precision (defined in (a)) is consisted of the sum of prior precision and data precision, as the prior precision becomes 0, only data precision contributes to the posterior precision:<br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma_{\\theta|d}&=[F^{\\top}\\Sigma_{d|\\theta}^{-1}F+\\Sigma_{\\theta\\theta}^{-1}]^{-1} \\\\\n",
    "&=[F^{\\top}\\Sigma_{d|\\theta}^{-1}F]^{-1}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.3** (Comparison with Least Squares Regression) Compare the limits obtained in Question 4.2 with the standard least squares regression formula. Explain under what conditions the posterior mean $\\mu_{\\theta|d}$ reduces to the ordinary least squares estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**<br>\n",
    "When the covariance $\\Sigma_{d|\\theta}$ is proportional to the identity matrix, for example, $\\Sigma_{d|\\theta} = \\sigma^2 I$ (homoscedastic, uncorrelated noise).<br>\n",
    "In this case:<br>\n",
    "$\\Sigma_{d|\\theta}^{-1} = \\frac{1}{\\sigma^2}I$<br>\n",
    "$\\mu_{\\theta|d} = \\frac{F^{\\top}\\frac{1}{\\sigma^2}Id}{F^{\\top}\\frac{1}{\\sigma^2}IF} = (F^{\\top}F)^{-1}F^{\\top}d = \\hat{\\theta}_{\\text{OLS}}$<br>\n",
    "$\\Sigma_{\\theta|d} = (F^{\\top}\\frac{1}{\\sigma^2}IF)^{-1} = \\sigma^2(F^{\\top}F)^{-1} = \\Sigma_{OLS}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.4** (Curve fitting and experimental design) In lectures we showed\n",
    "that by solving the Gaussian model we have solved the general linear fitting\n",
    "problem for arbitrary functions. Here you will calculate an example with an\n",
    "m-th order polynomial fit to l data points,\n",
    "\n",
    "$$d_i = \\sum_{j=0}^{j=m} s_j x_i^j + n_i \\quad i = 0, \\ldots, l-1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Following the lecture notes, write this curve fitting problem as a general\n",
    "linear model $d = As$ and hence identify the elements of $A_{ij}$ in terms of\n",
    "the values of x where the data are taken.<br>\n",
    "**Ans:**<br>\n",
    "To write this problem as a general linear model, we will need to identify $A$:<br>\n",
    "Since $d_i = \\sum_{j=0}^{j=m} s_j x_i^j$, $A$ is then a collection with elements $A_{ij}=${$x_i^j$}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Using the expressions you know for the conditional mean and conditional covariance of multivariate Gaussian pdfs (or otherwise), write down the solution for the posterior mean $\\mu_{s|d}$ and the posterior covariance $C_{s|d}$ in terms of the data vector $d$, prior covariance $C_{ss}$, the noise covariance $C_{nn}$, and $A$. Don’t yet plug in the special form of $A$ from this model.<br>\n",
    "**Ans:**<br>\n",
    "$$\n",
    "(\\mu_{d|s})_i = \\mathbb{E}[\\sum_{j=0}^{j=m} s_j x_i^j + n_i] = \\sum_{j=0}^{j=m} s_j x_i^j + 0 = As\\\\\n",
    "$$\n",
    "Rewrite the problem to $d=As+n$, we can compute the cross covariance as:<br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma_{ds}&=\\mathbb{E}[(d-\\mu_d)(s-\\mu_{s})^{\\top}] \\\\\n",
    "&= \\mathbb{E}[ds^{\\top}] \\\\\n",
    "&= \\mathbb{E}[(As+n)s^{\\top}] \\text{, noise is independent} \\\\\n",
    "&= \\mathbb{E}[A s s^{\\top}] \\\\\n",
    "&= A C_{ss}\n",
    "\\end{aligned}\n",
    "$$<br>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma_{dd}&=\\mathbb{E}[(d-\\mu_d)(d-\\mu_{d})^{\\top}] \\\\\n",
    "&= C_{nn}+AC_{ss}A^{\\top}\n",
    "\\end{aligned}\n",
    "$$<br>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{s|d}&=\\mu_s+\\Sigma_{sd}\\Sigma_{dd}^{-1}(d-\\mu_d) \\\\\n",
    "&= C_{ss} A^{\\top}(C_{nn}+AC_{ss}A^{\\top})^{-1}d\n",
    "\\end{aligned}\n",
    "$$<br>\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\Sigma_{s|d}&=C_{ss} - \\Sigma_{ds}^{\\top}\\Sigma_{dd}^{-1}\\Sigma_{ds} \\\\\n",
    "&= C_{ss} - C_{ss} A^{\\top} (C_{nn}+AC_{ss}A^{\\top})^{-1}AC_{ss}\n",
    "\\end{aligned}\n",
    "$$<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. We will consider a straight line fit to two data points, $m = 1$, $l = 2$. Assume that $x_0 = 0$ and $x_1 = 1$. Calculate the numerical values of the matrix elements $A_{ij}$.\n",
    "\n",
    "**Ans:**<br>\n",
    "$$d_i = \\sum_{j=0}^{1} s_j x_i^j + n_i \\quad i = 0, \\ldots, 1$$\n",
    "$A_{ij} = x_i^j$ where $i \\in \\{0,1\\}$ and $j \\in \\{0,1\\}$\n",
    "\n",
    "$A_{00} = x_0^0 = 0^0 = 1$<br>\n",
    "$A_{01} = x_0^1 = 0^1 = 0$<br>\n",
    "$A_{10} = x_1^0 = 1^0 = 1$<br>\n",
    "$A_{11} = x_1^1 = 1^1 = 1$<br>\n",
    "\n",
    "Therefore, $A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Hence, calculate the posterior mean $\\mu_{s|d}$ of the fitting parameters, the (offset and slope) $s_0$ and $s_1$. As data take $d_0 = 1$, $d_1 = 1$. Assume that the measurements are uncorrelated and the noise variance is $\\sigma^2 = 1$ for both measurements. You may also assume that the prior mean $\\mu_s = (0,0)^T$ and the prior covariance $C_{ss} = 4 I$ (i.e., four times the unit matrix)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**<br>\n",
    "\n",
    "The formula for posterior mean:\n",
    "$\\mu_{s|d} = C_{ss}A^T(C_{nn} + AC_{ss}A^T)^{-1}d$\n",
    "\n",
    "First, let's compute each component:\n",
    "$C_{ss}A^T = 4I \\cdot \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 4 & 4 \\\\ 0 & 4 \\end{bmatrix}$\n",
    "\n",
    "$AC_{ss}A^T = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} \\cdot 4I \\cdot \\begin{bmatrix} 1 & 1 \\\\ 0 & 1 \\end{bmatrix} = 4\\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\end{bmatrix}$\n",
    "\n",
    "$C_{nn} + AC_{ss}A^T = I + 4\\begin{bmatrix} 1 & 1 \\\\ 1 & 2 \\end{bmatrix} = \\begin{bmatrix} 5 & 4 \\\\ 4 & 9 \\end{bmatrix}$\n",
    "\n",
    "$(C_{nn} + AC_{ss}A^T)^{-1} = \\begin{bmatrix} 5 & 4 \\\\ 4 & 9 \\end{bmatrix}^{-1} = \\frac{1}{5 \\cdot 9 - 4 \\cdot 4}\\begin{bmatrix} 9 & -4 \\\\ -4 & 5 \\end{bmatrix} = \\frac{1}{29}\\begin{bmatrix} 9 & -4 \\\\ -4 & 5 \\end{bmatrix}$\n",
    "\n",
    "$\\mu_{s|d} = \\begin{bmatrix} 4 & 4 \\\\ 0 & 4 \\end{bmatrix} \\cdot \\frac{1}{29}\\begin{bmatrix} 9 & -4 \\\\ -4 & 5 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "$= \\frac{1}{29}\\begin{bmatrix} 4(9-4) & 4(-4+5) \\\\ 0(9-4) & 4(-4+5) \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$\n",
    "\n",
    "$= \\frac{1}{29}\\begin{bmatrix} 20 & 4 \\\\ 0 & 4 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\frac{1}{29}\\begin{bmatrix} 24 \\\\ 4 \\end{bmatrix} = \\begin{bmatrix} \\frac{24}{29} \\\\ \\frac{4}{29} \\end{bmatrix}$\n",
    "\n",
    "Therefore, $\\mu_{s|d} = [\\frac{24}{29}, \\frac{4}{29}]^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Calculate the posterior covariance $C_{s|d}$ of the fit parameters. Are the measurements of the offset $s_0$ and slope $s_1$ correlated or uncorrelated?\n",
    "\n",
    "**Ans:**<br>\n",
    "The formula for posterior covariance:\n",
    "$\\Sigma_{s|d} = C_{ss} - C_{ss}A^T(C_{nn} + AC_{ss}A^T)^{-1}AC_{ss}$\n",
    "\n",
    "We've already computed:\n",
    "- $C_{ss} = 4I$\n",
    "- $C_{ss}A^T = \\begin{bmatrix} 4 & 4 \\\\ 0 & 4 \\end{bmatrix}$\n",
    "- $(C_{nn} + AC_{ss}A^T)^{-1} = \\frac{1}{29}\\begin{bmatrix} 9 & -4 \\\\ -4 & 5 \\end{bmatrix}$\n",
    "\n",
    "Now we need to compute:\n",
    "$AC_{ss} = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\end{bmatrix} \\cdot 4I = \\begin{bmatrix} 4 & 0 \\\\ 4 & 4 \\end{bmatrix}$\n",
    "\n",
    "Continuing with the posterior covariance calculation:\n",
    "$C_{ss}A^T(C_{nn} + AC_{ss}A^T)^{-1}AC_{ss} = \\begin{bmatrix} 4 & 4 \\\\ 0 & 4 \\end{bmatrix} \\cdot \\frac{1}{29}\\begin{bmatrix} 9 & -4 \\\\ -4 & 5 \\end{bmatrix} \\cdot \\begin{bmatrix} 4 & 0 \\\\ 4 & 4 \\end{bmatrix}$\n",
    "\n",
    "$= \\frac{1}{29}\\begin{bmatrix} 4(9) + 4(-4) & 4(-4) + 4(5) \\\\ 0(9) + 4(-4) & 0(-4) + 4(5) \\end{bmatrix} \\cdot \\begin{bmatrix} 4 & 0 \\\\ 4 & 4 \\end{bmatrix}$\n",
    "\n",
    "$= \\frac{1}{29}\\begin{bmatrix} 20 & 4 \\\\ -16 & 20 \\end{bmatrix} \\cdot \\begin{bmatrix} 4 & 0 \\\\ 4 & 4 \\end{bmatrix}$\n",
    "\n",
    "$= \\frac{1}{29}\\begin{bmatrix} 20 \\cdot 4 + 4 \\cdot 4 & 20 \\cdot 0 + 4 \\cdot 4 \\\\ -16 \\cdot 4 + 20 \\cdot 4 & -16 \\cdot 0 + 20 \\cdot 4 \\end{bmatrix} = \\frac{1}{29}\\begin{bmatrix} 96 & 16 \\\\ 16 & 80 \\end{bmatrix}$\n",
    "\n",
    "So $\\Sigma_{s|d} = 4I - \\frac{1}{29}\\begin{bmatrix} 96 & 16 \\\\ 16 & 80 \\end{bmatrix} = \\begin{bmatrix} 4 - \\frac{96}{29} & -\\frac{16}{29} \\\\ -\\frac{16}{29} & 4 - \\frac{80}{29} \\end{bmatrix} = \\begin{bmatrix} \\frac{116-96}{29} & -\\frac{16}{29} \\\\ -\\frac{16}{29} & \\frac{116-80}{29} \\end{bmatrix} = \\begin{bmatrix} \\frac{20}{29} & -\\frac{16}{29} \\\\ -\\frac{16}{29} & \\frac{36}{29} \\end{bmatrix}$\n",
    "\n",
    "Since the off-diagonal elements of the posterior covariance matrix are non-zero (-16/29), the measurements of the offset $s_0$ and slope $s_1$ are correlated. Specifically, they have a negative correlation, meaning that as one parameter increases, the other tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (optional). Use the Sherman Morrison Woodbury identity\n",
    "\n",
    "   $$\n",
    "   M - M U^T (N + U M U^T)^{-1} V M = (M^{-1} + U^T N^{-1} U)^{-1}\n",
    "   $$\n",
    "   to derive from the expression for $C_{s|d}$ the alternative expression\n",
    "\n",
    "$$\n",
    "C_{s|d} = (C_{ss}^{-1} + A^T C_{nn}^{-1} A)^{-1}\n",
    "$$ \n",
    "\n",
    "**Ans:**<br>\n",
    "The original formula $\\Sigma_{s|d} = C_{ss} - C_{ss}A^T(C_{nn} + AC_{ss}A^T)^{-1}AC_{ss}$.<br>\n",
    "Just use Hua's identity we will get the alternative expression:<br>\n",
    "$$\n",
    "C_{s|d} = (C_{ss}^{-1} + A^T C_{nn}^{-1} A)^{-1}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. From Eq. (4.45) derive the form of the posterior covariance for no prior knowledge, _i.e._, infinite prior covariance $C_{ss} \\to \\infty$.\n",
    "\n",
    "**Ans:**\n",
    "No prior knowledge leads to prior precision $C_{ss}$ to 0, which is:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "C_{s|d} &= (C_{ss}^{-1} + A^T C_{nn}^{-1} A)^{-1} \\\\\n",
    "&=(A^T C_{nn}^{-1} A)^{-1}\n",
    "\\end{aligned}\n",
    "$$ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
